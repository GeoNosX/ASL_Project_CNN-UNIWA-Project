ASL Recognition Project â€“ University of West Attica

As part of my academic work at the University of West Attica, I completed a project focused on American Sign Language (ASL) recognition using computer vision and deep learning techniques. The primary objective of the project was to develop a system capable of identifying and classifying hand gestures corresponding to ASL alphabet signs in real time.

To achieve this, I built a convolutional neural network (CNN) trained on a dataset of labeled ASL hand gestures. The model was designed to process input images, extract key features, and classify them into the correct alphabet category. Throughout the project, I utilized tools such as Python, TensorFlow/Keras, OpenCV for image preprocessing, and various data augmentation techniques to improve generalization.

The final model achieved 99.89 accuracy on the validation set, demonstrating strong potential for practical applications in accessibility technology, such as aiding communication for individuals with hearing or speech impairments.

This project allowed me to apply theoretical knowledge from my AI and Deep Learning studies at UniWA and gain hands-on experience in model training, evaluation, and optimization. It also deepened my interest in using AI to build inclusive technologies.
